{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNh8H2o4C7+YJ5kASjgtm16",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayakumar1305/Spark1/blob/main/SparkSQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SparkSQL\n"
      ],
      "metadata": {
        "id": "vlyUulBINfm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, MapType\n",
        "\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"first_name\", StringType(), True),\n",
        "    StructField(\"last_name\", StringType(), True),\n",
        "    StructField(\"email\", StringType(), True),\n",
        "    StructField(\"department\", StringType(), True),\n",
        "    StructField(\"salary\", IntegerType(), True),\n",
        "    StructField(\"bonus\", IntegerType(), True),\n",
        "    StructField(\"skills\", StringType(), True),\n",
        "    StructField(\"roles\", ArrayType(StringType()), True),\n",
        "    StructField(\"properties\", MapType(StringType(), StringType()), True),\n",
        "    StructField(\"joining_date\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Creating a DataFrame with the schema\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SparkSchemaExample\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"Alice\", \"Smith\", \"alice@gmail.com\", \"IT\", 6000, 1000, \"Python,Java\", [\"Manager\", \"Developer\"], {\"key1\": \"value1\", \"key2\": \"value2\"}, \"2021-06-15\"),\n",
        "    (2, \"Bob\", \"Brown\", \"bob@gmail.com\", \"HR\", 5000, None, \"Recruitment,HR\", [\"HR\", \"Manager\"], {\"key3\": \"value3\"}, \"2022-07-20\"),\n",
        "    (3, \"Charlie\", \"Davis\", \"charlie@gmail.com\", \"IT\", 7000, 1200, \"Python,Scala\", [\"Developer\"], {\"key4\": \"value4\"}, \"2019-03-10\"),\n",
        "    (4, \"David\", \"Wilson\", \"david@gmail.com\", \"Finance\", 4500, 800, \"Accounting,Excel\", [\"Analyst\"], {}, \"2020-11-25\"),\n",
        "    (5, \"Emma\", \"Johnson\", \"emma@gmail.com\", \"IT\", 5500, None, \"Python,SQL\", [\"Developer\"], {\"key5\": \"value5\", \"key6\": \"value6\"}, \"2023-01-05\")\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, schema)\n"
      ],
      "metadata": {
        "id": "4viMqPVJNhGJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x5a5vxwORJs",
        "outputId": "499d356f-74cf-4a7a-aaa0-76968cf9887f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+\n",
            "| id|first_name|last_name|            email|department|salary|bonus|          skills|               roles|          properties|joining_date|\n",
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+\n",
            "|  1|     Alice|    Smith|  alice@gmail.com|        IT|  6000| 1000|     Python,Java|[Manager, Developer]|{key1 -> value1, ...|  2021-06-15|\n",
            "|  2|       Bob|    Brown|    bob@gmail.com|        HR|  5000| NULL|  Recruitment,HR|       [HR, Manager]|    {key3 -> value3}|  2022-07-20|\n",
            "|  3|   Charlie|    Davis|charlie@gmail.com|        IT|  7000| 1200|    Python,Scala|         [Developer]|    {key4 -> value4}|  2019-03-10|\n",
            "|  4|     David|   Wilson|  david@gmail.com|   Finance|  4500|  800|Accounting,Excel|           [Analyst]|                  {}|  2020-11-25|\n",
            "|  5|      Emma|  Johnson|   emma@gmail.com|        IT|  5500| NULL|      Python,SQL|         [Developer]|{key5 -> value5, ...|  2023-01-05|\n",
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creta a spark dataframe to SQL table for temporary view"
      ],
      "metadata": {
        "id": "dWSis9yKQF3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"employees\")"
      ],
      "metadata": {
        "id": "WF6egmiOPd_e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from employees\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ3WBMq5QgVQ",
        "outputId": "0b2737c5-53d8-4f92-f8c8-f29256a1e5f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+\n",
            "| id|first_name|last_name|            email|department|salary|bonus|          skills|               roles|          properties|joining_date|\n",
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+\n",
            "|  1|     Alice|    Smith|  alice@gmail.com|        IT|  6000| 1000|     Python,Java|[Manager, Developer]|{key1 -> value1, ...|  2021-06-15|\n",
            "|  2|       Bob|    Brown|    bob@gmail.com|        HR|  5000| NULL|  Recruitment,HR|       [HR, Manager]|    {key3 -> value3}|  2022-07-20|\n",
            "|  3|   Charlie|    Davis|charlie@gmail.com|        IT|  7000| 1200|    Python,Scala|         [Developer]|    {key4 -> value4}|  2019-03-10|\n",
            "|  4|     David|   Wilson|  david@gmail.com|   Finance|  4500|  800|Accounting,Excel|           [Analyst]|                  {}|  2020-11-25|\n",
            "|  5|      Emma|  Johnson|   emma@gmail.com|        IT|  5500| NULL|      Python,SQL|         [Developer]|{key5 -> value5, ...|  2023-01-05|\n",
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, avg, count, max, min, col # Remove 'mi'\n",
        "\n",
        "# If you intended to use mutual information, it is not a built-in function.\n",
        "# You may need to implement it yourself or use a library that provides it.\n",
        "#\n",
        "# If you intended to use a different function, please replace 'mi' with the correct function name.\n",
        "# For example, if you meant 'min', change the line to:\n",
        "# from pyspark.sql.functions import sum, avg, count, min, max"
      ],
      "metadata": {
        "id": "w6ZtS7WOQpBp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, lit\n",
        "\n",
        "total_salary = df.agg(sum(\"salary\")).collect()[0][0]  # Calculate total salary\n",
        "df = df.withColumn(\"total_salary\", lit(total_salary))  # Add as a new column\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4rCyzpfRvxE",
        "outputId": "2b44e69e-7115-459d-e821-a9602d82a7b3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+------------+\n",
            "| id|first_name|last_name|            email|department|salary|bonus|          skills|               roles|          properties|joining_date|total_salary|\n",
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+------------+\n",
            "|  1|     Alice|    Smith|  alice@gmail.com|        IT|  6000| 1000|     Python,Java|[Manager, Developer]|{key1 -> value1, ...|  2021-06-15|       28000|\n",
            "|  2|       Bob|    Brown|    bob@gmail.com|        HR|  5000| NULL|  Recruitment,HR|       [HR, Manager]|    {key3 -> value3}|  2022-07-20|       28000|\n",
            "|  3|   Charlie|    Davis|charlie@gmail.com|        IT|  7000| 1200|    Python,Scala|         [Developer]|    {key4 -> value4}|  2019-03-10|       28000|\n",
            "|  4|     David|   Wilson|  david@gmail.com|   Finance|  4500|  800|Accounting,Excel|           [Analyst]|                  {}|  2020-11-25|       28000|\n",
            "|  5|      Emma|  Johnson|   emma@gmail.com|        IT|  5500| NULL|      Python,SQL|         [Developer]|{key5 -> value5, ...|  2023-01-05|       28000|\n",
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"total_salary\", lit(total_salary))  # Add as a new column\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb6cYYFiSby3",
        "outputId": "95abcff9-22af-40c1-ed64-8f7fb3d81112"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+------------+\n",
            "| id|first_name|last_name|            email|department|salary|bonus|          skills|               roles|          properties|joining_date|total_salary|\n",
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+------------+\n",
            "|  1|     Alice|    Smith|  alice@gmail.com|        IT|  6000| 1000|     Python,Java|[Manager, Developer]|{key1 -> value1, ...|  2021-06-15|       28000|\n",
            "|  2|       Bob|    Brown|    bob@gmail.com|        HR|  5000| NULL|  Recruitment,HR|       [HR, Manager]|    {key3 -> value3}|  2022-07-20|       28000|\n",
            "|  3|   Charlie|    Davis|charlie@gmail.com|        IT|  7000| 1200|    Python,Scala|         [Developer]|    {key4 -> value4}|  2019-03-10|       28000|\n",
            "|  4|     David|   Wilson|  david@gmail.com|   Finance|  4500|  800|Accounting,Excel|           [Analyst]|                  {}|  2020-11-25|       28000|\n",
            "|  5|      Emma|  Johnson|   emma@gmail.com|        IT|  5500| NULL|      Python,SQL|         [Developer]|{key5 -> value5, ...|  2023-01-05|       28000|\n",
            "+---+----------+---------+-----------------+----------+------+-----+----------------+--------------------+--------------------+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write in temporary sql method\n"
      ],
      "metadata": {
        "id": "ENnBdmJqUGgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\" select count(*), sum(salary), avg(salary), min(salary), max(salary) from employees\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANaFgxkZTIYt",
        "outputId": "bd4b0cb9-0235-4906-d31f-63d3259ad20b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+-----------+-----------+-----------+\n",
            "|count(1)|sum(salary)|avg(salary)|min(salary)|max(salary)|\n",
            "+--------+-----------+-----------+-----------+-----------+\n",
            "|       5|      28000|     5600.0|       4500|       7000|\n",
            "+--------+-----------+-----------+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COLLECT_LIST is use to collect all the rown and shows in single row output, truncate =False is used to show all the values in the list\n",
        "\n",
        "COLLECT_SET = remove the duplicates,\n",
        "COLLECT_LIST = keep the duplicates"
      ],
      "metadata": {
        "id": "pq-ShtF3VGTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT COLLECT_LIST(first_name) from employees\").show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xP1vVO6UD7a",
        "outputId": "a7707c8e-07af-4d82-c784-770bcf639ec4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+\n",
            "|collect_list(first_name)          |\n",
            "+----------------------------------+\n",
            "|[Alice, Bob, Charlie, David, Emma]|\n",
            "+----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT first_name from employees\").show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVrrn2zcU9Cf",
        "outputId": "3a02f3f3-ce43-4b20-9ed7-fdde8c280d4e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|first_name|\n",
            "+----------+\n",
            "|Alice     |\n",
            "|Bob       |\n",
            "|Charlie   |\n",
            "|David     |\n",
            "|Emma      |\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "array_contains -- it will check the array contains the value or not\n"
      ],
      "metadata": {
        "id": "bDLKIOPvV7vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select roles, array_contains(roles, 'Manager') from employees\").show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0l597VHVFzh",
        "outputId": "f56fff9e-c327-4f70-c9a6-e5b9eaa73a25"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------------------+\n",
            "|roles               |array_contains(roles, Manager)|\n",
            "+--------------------+------------------------------+\n",
            "|[Manager, Developer]|true                          |\n",
            "|[HR, Manager]       |true                          |\n",
            "|[Developer]         |false                         |\n",
            "|[Analyst]           |false                         |\n",
            "|[Developer]         |false                         |\n",
            "+--------------------+------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explode -- its an array, it can convert string to array\n",
        "\n",
        "explode can easily increase the no of function\n",
        "Size is to find no of element in arrays"
      ],
      "metadata": {
        "id": "3LMsPuvQWr8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select skills, split(skills,',') from employees\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTjLo4SuWZTb",
        "outputId": "6f5ab257-c3a4-403b-c43b-58eadc2185a8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+\n",
            "|skills          |split(skills, ,, -1)|\n",
            "+----------------+--------------------+\n",
            "|Python,Java     |[Python, Java]      |\n",
            "|Recruitment,HR  |[Recruitment, HR]   |\n",
            "|Python,Scala    |[Python, Scala]     |\n",
            "|Accounting,Excel|[Accounting, Excel] |\n",
            "|Python,SQL      |[Python, SQL]       |\n",
            "+----------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select skills,explode(split(skills,',')) from employees\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b7Twp8YXtUN",
        "outputId": "b6e8d6bf-d40b-4b9a-fd13-8ff39906af1a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----------+\n",
            "|skills          |col        |\n",
            "+----------------+-----------+\n",
            "|Python,Java     |Python     |\n",
            "|Python,Java     |Java       |\n",
            "|Recruitment,HR  |Recruitment|\n",
            "|Recruitment,HR  |HR         |\n",
            "|Python,Scala    |Python     |\n",
            "|Python,Scala    |Scala      |\n",
            "|Accounting,Excel|Accounting |\n",
            "|Accounting,Excel|Excel      |\n",
            "|Python,SQL      |Python     |\n",
            "|Python,SQL      |SQL        |\n",
            "+----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select skills , size(split(skills,',')) from employees\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhYYQZeOYAVy",
        "outputId": "b87604d7-fe78-4549-c469-8805adae560f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------------+\n",
            "|skills          |size(split(skills, ,, -1))|\n",
            "+----------------+--------------------------+\n",
            "|Python,Java     |2                         |\n",
            "|Recruitment,HR  |2                         |\n",
            "|Python,Scala    |2                         |\n",
            "|Accounting,Excel|2                         |\n",
            "|Python,SQL      |2                         |\n",
            "+----------------+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User defined function -- can create own taks"
      ],
      "metadata": {
        "id": "tYibycP5Yh46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg"
      ],
      "metadata": {
        "id": "R2wymc0vYIt0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masking the function"
      ],
      "metadata": {
        "id": "Jj_kSGXtY_p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_email(email):\n",
        "    return email[:3] + \"****@\" + email.split('@')[-1]"
      ],
      "metadata": {
        "id": "cRIRCywLYpCu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mask_email(\"jayakumar13@gmail.com\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN58f5lDZTEL",
        "outputId": "9cfb9c27-f4c4-4013-fc28-87557fec829a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jay****@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To add user defined function into spark section"
      ],
      "metadata": {
        "id": "79jW4vEpbNkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType"
      ],
      "metadata": {
        "id": "qTnMpuYqZehX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_email_udf = udf(mask_email, StringType())"
      ],
      "metadata": {
        "id": "vH78biR6bHpK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V-TUTGZIbTan"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}